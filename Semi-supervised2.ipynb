{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a25517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 10:38:03.650166: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-05 10:38:03.650642: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, recall_score, f1_score, accuracy_score, precision_score\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, LatentDirichletAllocation\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from typing import NoReturn, Union, List\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from umap import UMAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e332406b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17625113",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e9fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time and amount scaling\n",
    "df['Time'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "df['Amount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "df_anom = df[df['Class'] == 1]\n",
    "df_norm = df[df['Class'] == 0]\n",
    "\n",
    "if dev:\n",
    "    df_norm = df_norm.sample(5000, random_state=42)\n",
    "df_test_norm = df_norm.sample(df_anom.shape[0])\n",
    "df_test = pd.concat([\n",
    "    df_anom,\n",
    "    df_test_norm\n",
    "])\n",
    "df_train = df_norm.drop(df_test_norm.index)\n",
    "\n",
    "feature_cols = [_ for _ in df.columns if _ != 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32cb301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train: [  283823 x 30   ]\n",
      " test: [     984 x 30   ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train[feature_cols]\n",
    "y_train = df_train['Class'] # will not be used\n",
    "X_test = df_test[feature_cols]\n",
    "y_test = df_test['Class'] # for evaluation\n",
    "print('''\n",
    "train: [{:>8} x {:<5}]\n",
    " test: [{:>8} x {:<5}]\n",
    "'''.format(*X_train.shape, *X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b40c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity_keras(y_true, y_pred):\n",
    "    \"\"\"credits: https://datascience.stackexchange.com/a/40746/28592\n",
    "    \n",
    "    param:\n",
    "    y_pred - Predicted labels\n",
    "    y_true - True labels \n",
    "    Returns:\n",
    "    Specificity score\n",
    "    \"\"\"\n",
    "    neg_y_true = 1 - y_true\n",
    "    neg_y_pred = 1 - y_pred\n",
    "    fp = tf.keras.backend.sum(neg_y_true * y_pred)\n",
    "    tn = tf.keras.backend.sum(neg_y_true * neg_y_pred)\n",
    "    specificity = tn / (tn + fp + tf.keras.backend.epsilon())\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409d5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaled_IsolationForest(IsolationForest):\n",
    "    \"\"\"The purpose of this sub-class is to transform prediction values from {-1, 1} to {1,0}\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        pred = super().predict(X)\n",
    "        scale_func = np.vectorize(lambda x: 1 if x == -1 else 0)\n",
    "        return scale_func(pred)\n",
    "\n",
    "class Scaled_OneClass_SVM(OneClassSVM):\n",
    "    \"\"\"The purpose of this sub-class is to transform prediction values from {-1, 1} to {1,0}\n",
    "    \"\"\"\n",
    "    def predict(self, X):\n",
    "        return np.array([y==-1 for y in super().predict(X)])\n",
    "    \n",
    "class NoveltyDetection_Sequential(tf.keras.models.Sequential):\n",
    "    \"\"\"This custom `tf.keras.models.Sequential` sub-class transforms autoencoder's output into {1,0}.\n",
    "    Output value is determined based on reproduction (decode) loss. If reproduction loss is more than a threashold then, the input sample is considered as anomaly (outlier).\n",
    "    Based on few experiments, 1.5 is a dissent threashold (don't as why :P). Future work: determine the threashold using a more sophisticated method.\n",
    "    \"\"\"\n",
    "    def predict(self, x, *args, **kwargs):\n",
    "        pred = super().predict(x, *args, **kwargs)\n",
    "        mse = np.mean(np.power(x - pred, 2), axis=1)\n",
    "        scale_func = np.vectorize(lambda x: 1 if x > 1.5 else 0)\n",
    "        return scale_func(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "871b2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define early stop in order to prevent overfitting and useless training\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='mse',\n",
    "    patience=10,\n",
    "    verbose=1, \n",
    "    mode='min',\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# it's a common practice to store the best model\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='autoenc.hdf5',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "def get_autoencoder() -> tf.keras.models.Sequential:\n",
    "    \"\"\"Build an autoencoder\n",
    "    \"\"\"\n",
    "    model = NoveltyDetection_Sequential([\n",
    "        tf.keras.layers.Dense(X_train.shape[1], activation='relu', input_shape=(X_train.shape[1], )),\n",
    "        # add some noise to prevent overfitting\n",
    "        tf.keras.layers.GaussianNoise(0.05),\n",
    "        tf.keras.layers.Dense(2, activation='relu'),\n",
    "        tf.keras.layers.Dense(X_train.shape[1], activation='relu')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "                        loss='mse',\n",
    "                        metrics=['acc', sensitivity_keras])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c7d385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'isolation_forest': {\n",
    "        'label': 'Isolation Forest',\n",
    "        'clb': Scaled_IsolationForest,\n",
    "        'params': {\n",
    "            'contamination': 'auto',\n",
    "            'n_estimators': 300\n",
    "        },\n",
    "        'predictions': None,\n",
    "        'model': None\n",
    "    },\n",
    "    'ocsvm': {\n",
    "        'label': 'OneClass SVM',\n",
    "        'clb': Scaled_OneClass_SVM,\n",
    "        'params': {\n",
    "            'kernel': 'rbf',\n",
    "            'gamma': 0.3,\n",
    "            'nu': 0.01,\n",
    "        },\n",
    "        'prediction': None,\n",
    "        'model': None\n",
    "    },\n",
    "    'auto-encoder': {\n",
    "        'label': 'Autoncoder',\n",
    "        'clb': get_autoencoder,\n",
    "        'params': {},\n",
    "        'fit_params': {\n",
    "            'x': X_train, 'y': X_train,\n",
    "            'validation_split': 0.2,\n",
    "            'callbacks': [early_stop, checkpoint],\n",
    "            'epochs': 64,\n",
    "            'batch_size': 256,\n",
    "            'verbose': 0\n",
    "        },\n",
    "        'predictions': None,\n",
    "        'model': None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7f27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d6fb704af14631a6df9e0a25ef6196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "t = trange(len(clfs))\n",
    "for name in clfs:\n",
    "    t.set_description(clfs[name]['label'])\n",
    "    clfs[name]['model'] = clfs[name]['clb'](**clfs[name]['params'])\n",
    "    if 'fit_params' in clfs[name]:\n",
    "        clfs[name]['model'].fit(**clfs[name].get('fit_params', {}))\n",
    "    else:\n",
    "        clfs[name]['model'].fit(X_train)\n",
    "    clfs[name]['predictions'] = clfs[name]['model'].predict(X_test)\n",
    "    t.update()\n",
    "t.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f7d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval_metrics(y_true, y_pred, name='', header=True):\n",
    "    \"\"\"Function for printing purposes\n",
    "    \"\"\"\n",
    "    if header:\n",
    "        print('{:>20}\\t{:>10}\\t{:>10}\\t{:>8}\\t{:>5}'.format('Algorith', 'Accuracy', 'Recall', 'Precision', 'f1'))\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    print('{:>20}\\t{:>1.8f}\\t{:>1.8f}\\t{:>1.6f}\\t{:>1.3f}'.format(\n",
    "        name, acc, recall, prec, f1\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ec1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    Copyed from a kernel by joparga3 https://www.kaggle.com/joparga3/kernels\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ffede",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.column_stack([clfs[_]['predictions'] for _ in clfs])\n",
    "enseble_preds = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f22c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_vot = EnsembleVoteClassifier([clfs[_]['model'] for _ in clfs], fit_base_estimators=False)\n",
    "hard_vot.fit(X_test, y_test)\n",
    "enseble_preds.append((hard_vot.predict(X_test), 'Hard Voting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c60b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wei_hard_vot = EnsembleVoteClassifier([clfs[_]['model'] for _ in clfs], weights=[\n",
    "        0.4,\n",
    "        0.2,\n",
    "        0.8\n",
    "    ], fit_base_estimators=False)\n",
    "wei_hard_vot.fit(X_test, y_test)\n",
    "enseble_preds.append((wei_hard_vot.predict(X_test), 'Weighted Hard Voting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2476831",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "x_tr_ens, x_ts_ens, y_tr_ens, y_ts_ens = train_test_split(y_preds, y_test, test_size=.5)\n",
    "rf.fit(x_tr_ens, y_tr_ens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1458577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_header = True\n",
    "for k, v in clfs.items():\n",
    "    print_eval_metrics(y_test, v['predictions'], v['label'], print_header)\n",
    "    print_header = False\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for prds, l in enseble_preds:\n",
    "    print_eval_metrics(y_test, prds, l, print_header)\n",
    "    print_header = False\n",
    "\n",
    "print('\\n')\n",
    "    \n",
    "print_eval_metrics(\n",
    "    y_ts_ens,\n",
    "    rf.predict(x_ts_ens),\n",
    "    'Bleding using RF', False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "for k, v in clfs.items():\n",
    "    cnf = confusion_matrix(y_test, v['predictions'])\n",
    "    plot_confusion_matrix(cnf,classes=[\"0\",\"1\"], title=v[\"label\"])\n",
    "    \n",
    "for prds, l in enseble_preds:\n",
    "    cnf = confusion_matrix(y_test, prds)\n",
    "    plot_confusion_matrix(cnf,classes=[\"0\",\"1\"], title=l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3acb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a85af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4af835",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225240b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs[\"auto-encoder\"][\"predictions\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
